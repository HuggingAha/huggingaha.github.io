---
title: "译文-“思考”工具：使Claude在复杂的工具使用情况下能够停止并思考-Anthropic"
showAuthor: false
date: 2025-03-22
description: "构建高效AI Agent-Anthropic"
slug: "claude-think-tool-translate"
tags: ["翻译", "Agent", "think-tool", "Anthropic"]
# series: [""]
# series_order: 1
draft: false
---

<!-- 渲染公式 -->
{{< katex >}}


# **“思考”工具：让 Claude 在复杂的工具使用场景中停下来思考**

> 原文：[engineering/claude-think-tool](https://www.anthropic.com/engineering/claude-think-tool)
> 

{{< alert "bell" >}}
**一种能提升 Claude 解决复杂问题能力的新工具**
{{< /alert >}}


在我们持续增强 Claude 解决复杂问题能力的过程中，我们发现了一种特别有效的方法：一个“思考”工具（"think" tool）。该工具在处理复杂任务时，为结构化思考创造了一个专门的空间。

这项技术虽然简单但功能强大——我们稍后会解释，它不同于 Claude 新的“[扩展思考](https://www.anthropic.com/research/visible-extended-thinking)”能力——它显著提升了 Claude 在作为代理（agent）使用工具时的能力。这包括遵守策略、做出一致的决策以及处理多步骤问题，所有这些都只需极低的实现开销。

在本文中，我们将探讨如何在不同的应用程序中实现“思考”工具，并基于经过验证的基准测试结果，为开发者分享实践指导。

### 什么是“思考”工具？

通过“思考”工具，我们赋予了 Claude 在得出最终答案的过程中，增加一个额外思考步骤的能力——这个步骤有其自己指定的空间。

虽然这听起来与“扩展思考”（extended thinking）相似，但它们是不同的概念。“扩展思考”关注的是 Claude 在开始生成回应**之前**所做的事情。通过“扩展思考”，Claude 会在采取行动前深入思考并迭代其计划。而“思考”工具则是让 Claude 在**开始生成回应后**，增加一个步骤来停下来思考它是否掌握了继续前进所需的所有信息。这在执行长链条的工具调用或与用户进行长时间的多步骤对话时尤其有用。

这使得“思考”工具更适用于 Claude 仅凭用户查询无法获得 formulating a response所需全部信息，并且需要处理外部信息（例如，工具调用结果中的信息）的场景。Claude 使用“思考”工具进行的推理，其全面性不如“扩展思考”，它更侧重于模型发现的新信息。

我们建议在更简单的工具使用场景中使用“扩展思考”，例如非序列化的工具调用或直接的指令遵循。“扩展思考”也适用于那些你不需要 Claude 调用工具的用例，如编码、数学和物理。而“思考”工具则更适合以下情况：Claude 需要调用复杂的工具，在长链条的工具调用中仔细分析工具输出，在充满详细指导、策略繁重的环境中导航，或者做出序列化的决策（其中每一步都建立在前一步的基础上，且错误代价高昂）。

以下是一个使用 [τ-Bench](https://arxiv.org/abs/2406.12045) 标准工具规范格式的示例实现：

```json
{
  "name": "think",
  "description": "使用此工具进行思考。它不会获取新信息或更改数据库，只是将思考内容附加到日志中。在需要复杂推理或某种缓存记忆时使用。",
  "input_schema": {
    "type": "object",
    "properties": {
      "thought": {
        "type": "string",
        "description": "需要思考的内容。"
      }
    },
    "required": ["thought"]
  }
}
```

### **在 τ-Bench 上的性能表现**

我们使用 τ-bench (tau-bench) 对“思考”工具进行了评估。这是一个全面的基准测试，旨在测试模型在真实客服场景中使用工具的能力，其中“思考”工具是评估标准环境的一部分。

τ-bench 评估 Claude 在以下方面的能力：

- 与模拟用户进行真实的对话导航
- 始终如一地遵循复杂的客服代理策略指南
- 使用多种工具访问和操作环境数据库

τ-bench 中使用的主要评估指标是 `pass^k`，它衡量的是对于一个给定的任务，所有 `k` 次独立任务试验都成功的概率，并在所有任务中取平均值。与其它 LLM 评估中常见的 `pass@k` 指标（衡量 `k` 次试验中至少有一次成功）不同，`pass^k` 评估的是**一致性**和**可靠性**——这对于客服应用至关重要，因为在这些应用中，持续遵守策略是必不可少的。

### **性能分析**

我们的评估比较了几种不同的配置：

- **基准** (无“思考”工具，无“扩展思考”模式)
- **仅扩展思考模式**
- **仅“思考”工具**
- **带优化提示的“思考”工具** (针对航空领域)

结果显示，当 Claude 3.7 在基准测试的“航空”和“零售”客服领域有效使用“思考”工具时，性能得到了显著提升：

- **航空领域**: 带有优化提示的“思考”工具在 `pass^1` 指标上达到了 0.570，而基准仅为 0.370——相对提升了 54%。
- **零售领域**: 仅使用“思考”工具就达到了 0.812，而基准为 0.783。

<figure>
  <img src="https://cdn.jsdelivr.net/gh/gongzitaiyi/picture@master/uPic/2025/12/NIltQ0.png" alt="Claude 3.7 Sonnet 在 τ-Bench “航空”领域的性能评估">
  <figcaption style="text-align: center;">Claude 3.7 Sonnet 在 τ-Bench “航空”领域的性能评估</figcaption>
</figure>


**Claude 3.7 Sonnet 在 τ-Bench “航空”领域评估中的表现**

| 配置 | k=1 | k=2 | k=3 | k=4 | k=5 |
| --- | --- | --- | --- | --- | --- |
| **"思考" + 提示** | **0.584** | **0.444** | **0.384** | **0.356** | **0.340** |
| "思考" | 0.404 | 0.254 | 0.186 | 0.140 | 0.100 |
| 扩展思考 | 0.412 | 0.290 | 0.232 | 0.192 | 0.160 |
| 基准 | 0.332 | 0.206 | 0.148 | 0.116 | 0.100 |

在航空领域，最佳性能是通过将“思考”工具与一个优化的提示（prompt）相结合实现的，该提示给出了分析客户请求时可以使用的推理方法示例。以下是优化提示的示例：

```
## 使用思考工具
在收到工具结果后，采取任何行动或回应用户之前，使用思考工具作为草稿来：
- 列出适用于当前请求的具体规则
- 检查是否已收集所有必需信息
- 验证计划中的行动是否符合所有政策
- 迭代检查工具结果的正确性

以下是一些在思考工具内部可以迭代思考的例子：
<think_tool_example_1>
用户想取消航班 ABC123
- 需要验证：用户ID，预订ID，原因
- 检查取消规则：
  * 是否在预订后24小时内？
  * 如果不是，检查票务等级和保险
- 验证没有航段已飞行或已过期
- 计划：收集缺失信息，验证规则，获取确认
</think_tool_example_1>

<think_tool_example_2>
用户想预订3张去纽约的机票，每人2件托运行李
- 需要用户ID来检查：
  * 会员等级对应的行李额度
  * 个人资料中有哪些支付方式
- 行李计算：
  * 经济舱 × 3位乘客
  * 如果是普通会员：每人1件免费行李 → 额外3件行李 = $150
  * 如果是银卡会员：每人2件免费行李 → 额外0件行李 = $0
  * 如果是金卡会员：每人3件免费行李 → 额外0件行李 = $0
- 支付规则验证：
  * 最多1张旅行券，1张信用卡，3张礼品卡
  * 所有支付方式必须在个人资料中
  * 旅行券余额将作废
- 计划：
  1. 获取用户ID
  2. 验证会员等级以确定行李费
  3. 检查个人资料中的支付方式及其组合是否允许
  4. 计算总费用：票价 + 任何行李费
  5. 获取明确的预订确认
</think_tool_example_2>

```

特别有趣的是不同方法的比较。使用带优化提示的“思考”工具比“扩展思考”模式（其表现与未加提示的“思考”工具相似）取得了明显更好的结果。仅使用“思考”工具（无提示）比基准有所提升，但仍不及优化后的方法。

“思考”工具与优化提示的结合，以显著优势取得了最强的性能，这可能是因为基准测试的航空公司策略部分高度复杂，模型从给定的“如何思考”的示例中获益最多。

在零售领域，我们同样测试了多种配置以理解每种方法具体的影响。

<figure>
  <img src="https://cdn.jsdelivr.net/gh/gongzitaiyi/picture@master/uPic/2025/12/10Bara.png" alt="Claude 3.7 Sonnet τ-Bench “零售”领域评估">
  <figcaption style="text-align: center;">Claude 3.7 Sonnet τ-Bench “零售”领域评估</figcaption>
</figure>


**Claude 3.7 Sonnet 在 τ-Bench “零售”领域评估中的性能**

| 配置 | k=1 | k=2 | k=3 | k=4 | k=5 |
| --- | --- | --- | --- | --- | --- |
| **"思考" + 无提示** | **0.812** | **0.735** | **0.685** | **0.650** | **0.626** |
| 扩展思考 | 0.770 | 0.681 | 0.623 | 0.581 | 0.548 |
| 基准 | 0.783 | 0.695 | 0.643 | 0.607 | 0.583 |

即便没有额外的提示，“思考”工具也取得了最高的 `pass^1` 分数 0.812。零售领域的策略显然比航空领域更容易导航，Claude 仅通过拥有一个思考空间就能得到提升，无需进一步指导。

### **从 τ-Bench 分析中得出的关键洞见**

我们的详细分析揭示了几个模式，可以帮助你有效地实现“思考”工具：

- **在困难领域，提示至关重要**。仅仅提供“思考”工具可能会在一定程度上提升性能，但将其与优化的提示相结合，在困难领域会产生显著更好的结果。然而，较简单的领域可能仅从拥有“思考”能力中就能获益。
- **跨试验的一致性得到改善**。使用“思考”工具带来的提升在 `pass^k`（`k` 最高到5）中都得以保持，这表明该工具有助于 Claude 更有效地处理边缘案例和异常场景。

### **在 SWE-Bench 上的性能表现**

在评估 Claude 3.7 Sonnet 时，一个类似的“思考”工具被添加到了我们的 SWE-bench 设置中，为其取得 0.623 的当前最佳成绩做出了贡献。调整后的“思考”工具定义如下：

```json
{
  "name": "think",
  "description": "使用此工具进行思考。它不会获取新信息或对代码仓库做任何更改，只是记录思考过程。在需要复杂推理或头脑风暴时使用。例如，如果你在探索代码库并发现了 bug 的来源，调用此工具来头脑风暴几种独特的修复方法，并评估哪种更改可能最简单有效。或者，如果你收到一些测试结果，调用此工具来头脑风暴如何修复失败的测试。",
  "input_schema": {
    "type": "object",
    "properties": {
      "thought": {
        "type": "string",
        "description": "你的思考内容。"
      }
    },
    "required": ["thought"]
  }
}
```

我们的实验（n=30 个样本使用“思考”工具，n=144 个样本不使用）显示，单独包含此工具的效果平均提升了 1.6% 的性能。

### **何时使用“思考”工具**

基于这些评估结果，我们确定了 Claude 能从“思考”工具中获益最多的具体场景：

- **工具输出分析**。当 Claude 在行动前需要仔细处理前一个工具调用的输出，并可能需要回溯其方法时。
- **策略繁重的环境**。当 Claude 需要遵循详细的指导方针并验证合规性时。
- **序列化决策**。当每个行动都建立在前一个行动之上，且错误代价高昂时（常见于多步骤领域）。

### **实施最佳实践**

为了充分利用 Claude 的“思考”工具，我们根据 τ-bench 实验推荐以下实施实践。

1. **使用特定领域的示例进行策略性提示**
提供关于何时以及如何使用“思考”工具的明确指令，是最有效的方法，就像用于 τ-bench 航空领域的那个一样。提供针对你特定用例的示例，能显著提高模型使用“思考”工具的效率：
    - 推理过程中期望的详细程度；
    - 如何将复杂指令分解为可操作的步骤；
    - 处理常见场景的决策树；
    - 如何检查是否已收集所有必要信息。
2. **将复杂的指导放在系统提示中**
我们发现，当关于“思考”工具的指令很长和/或复杂时，将其包含在**系统提示**中比放在工具描述本身更有效。这种方法提供了更广阔的上下文，并帮助模型更好地将思考过程融入其整体行为中。

### **何时不使用“思考”工具**

尽管“思考”工具可以带来显著的改进，但它并不适用于所有的工具使用场景，并且会增加提示长度和输出 token 的成本。具体来说，我们发现在以下用例中，“思考”工具没有任何改进：

- **非序列化工具调用**。如果 Claude 只需要进行单个工具调用或多个并行调用来完成任务，增加“思考”不太可能有任何改进。
- **简单的指令遵循**。当没有太多约束需要 Claude 遵守，且其默认行为已足够好时，额外的“思考”不太可能带来收益。

### **开始使用**

“思考”工具是对你的 Claude 实现的一个直接补充，只需几个步骤就能带来有意义的改进：

1. **在代理式工具使用场景中进行测试**。从具有挑战性的用例开始——那些 Claude 目前在遵守策略或在长工具调用链中进行复杂推理时遇到困难的场景。
2. **添加工具定义**。实现一个为你的领域定制的“思考”工具。它只需要最少的代码，但能实现更结构化的推理。同时，考虑在系统提示中加入关于何时以及如何使用该工具的说明，并附上与你领域相关的示例。
3. **监控和优化**。观察 Claude 在实践中如何使用该工具，并调整你的提示以鼓励更有效的思考模式。

最好的部分是，添加这个工具在性能结果方面几乎没有负面影响。除非 Claude 决定使用它，否则它不会改变外部行为，也不会干扰你现有的工具或工作流程。

### **结论**

我们的研究表明，“思考”工具可以显著提升 Claude 3.7 Sonnet¹ 在需要遵守策略和在长链条工具调用中进行推理的复杂任务上的性能。“思考”并非万能解决方案，但对于正确的用例，它能带来巨大的好处，且实现复杂度极低。

我们期待看到您将如何使用“思考”工具，来构建更强大、更可靠、更透明的 AI 系统。

---

¹ 虽然我们的 τ-Bench 结果侧重于 Claude 3.7 Sonnet 使用“思考”工具的改进，但我们的实验表明，Claude 3.5 Sonnet（新版）也能通过与 3.7 Sonnet 相同的配置实现性能增益，这表明这种改进也适用于其他 Claude 模型。
