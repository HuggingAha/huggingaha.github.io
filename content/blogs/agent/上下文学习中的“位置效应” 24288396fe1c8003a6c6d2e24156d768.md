---
title: "上下文学习中的“位置效应”"
showAuthor: false
date: 2025-08-01
description: "上下文学习中的“位置效应”"
slug: "bICL-Prompt-Positional-Bias"
tags: ["论文", "ContextEngineering", "LLM", "Prompt"]
# series: [""]
# series_order: 1
draft: false
---

<!-- 渲染公式 -->
{{< katex >}}


<!-- # 上下文学习中的“位置效应” -->

<figure>
  <img src="https://cdn.jsdelivr.net/gh/gongzitaiyi/picture@master/uPic/2025/12/mFOYJ4.png" alt="paper">
  <figcaption style="text-align: center;"></figcaption>
</figure>

{{< alert "arxiv" >}}
[Where to show Demos in Your Prompt: A Positional Bias of In-Context Learning](https://arxiv.org/abs/2507.22887)
{{< /alert >}}

本文源自Cobbina和Zhou (2025)发表的*研究*《Where to show Demos in Your Prompt: A Positional Bias of In-Context Learning》。该研究首次系统性地揭示并量化了大型语言模型（LLM）中一种新颖且重要的现象——“样例位置偏见”（Demos' Position in Prompt Bias, DPP Bias），即上下文学习（ICL）中，示例（demos）在提示语中的空间位置对模型性能和预测稳定性产生的巨大影响。本文将遵循“理解先于评判”的原则，首先梳理该论文的研究框架、核心方法与关键发现，随后结合建设性质疑，探讨其理论贡献、方法论稳健性及未来研究方向。


## 1. 研究背景与核心问题

上下文学习（In-Context Learning, ICL）已成为现代大型语言模型的核心能力之一，它允许模型在不更新参数的情况下，仅通过在提示语中提供少量示例来适应新任务。然而，ICL的性能表现出显著的“脆弱性”，对提示语的细微变化高度敏感。**虽然已有研究（如 Lu et al., 2022）深入探讨了示例内容的选择（demo selection）和示例内部的排列顺序（internal permutation of demos）对模型性能的影响，但Cobbina与Zhou的这项工作则另辟蹊径，将目光投向了一个更基本却被长期忽视的维度：将内容和顺序完全固定的示例模块作为一个整体，其在提示语中的外部放置位置（external placement）会产生何种影响？**

Cobbina与Zhou敏锐地捕捉到这一研究空白。他们提出的核心问题是：

> 在一个结构化的提示语（如包含系统指令和用户查询的对话格式）中，将内容完全相同的示例模块放置在不同位置，是否会影响模型的输出？如果会，这种影响的模式、规模和内在机制是什么？
> 

该论文将这种纯粹由空间位置（spatial placement）而非内容引发的性能波动，定义为**DPP偏见**。这一问题的提出具有重大的理论与实践价值，因为它**直接挑战了“LLM能够以位置无关的方式稳健整合上下文信息”这一基础假设**。若此假设不成立，则当前大量的提示工程实践可能缺乏坚实的理论基础，模型的可靠性和可复现性也将面临严重考验。

## **2. 理论基础与方法解读**

为系统性地研究DPP偏见，作者们设计了一套严谨的评估框架，包括明确的问题形式化、规范化的位置定义以及创新的评估指标。

### **2.1 问题形式化与位置定义**

研究的核心在于**精密的变量控制**。作者们在实验中保持提示语的所有内容要素——系统指令、用户查询、以及示例本身——完全不变，仅改变示例模块（demo block）的插入位置。这种设计有效地将性能变化归因于唯一变量：**位置**。

作者利用当前主流的指令微调模型普遍采用的“对话式”模板，定义了四种具有代表性的规范化位置（Canonical Demo Positions）：

| 位置标识 | 全称 | 描述 | 结构示意图 |
| --- | --- | --- | --- |
| **ssp** | Start of System Prompt | 示例置于**系统指令之前**，是整个提示语的最前端。 | `[Demos] [System Instructions] <user> [Query]` |
| **esp** | End of System Prompt | 示例置于**系统指令之后**，但在用户消息之前。 | `[System Instructions] [Demos] <user> [Query]` |
| **sum** | Start of User Message | 示例置于**用户消息的开头**，但在实际查询之前。（被视为默认位置） | `[System Instructions] <user> [Demos] [Query]` |
| **eum** | End of User Message | 示例置于**用户查询之后**，是整个提示语的末尾。 | `[System Instructions] <user> [Query] [Demos]` |

这四种位置的划分逻辑清晰，覆盖了示例与系统指令和用户查询的主要相对关系（之前/之后），为系统性探究提供了坚实基础。

> 🔍 **方法疑问**: 论文将 `sum` (Start of User Message) 设定为计算预测变化率（Prediction Change）时的“默认”基准。这一选择的依据是什么？虽然许多提示模板确实将示例放在用户查询前，但将其奉为“默认标准”可能是一种先验假设。如果选择一个理论上更优的位置（如本文发现的 `ssp`）作为基准，可能会揭示出从“最优”到“次优”位置的性能衰减模式，从而提供不同维度的洞察。
> 

### **2.2 创新诊断指标**

除了任务相关的标准指标（如准确率、F1值、ROUGE等），作者引入了两个任务无关的诊断性指标，用以量化DPP偏见的影响：

1. **准确率变化 (Accuracy Change, \(∆_{metric}\))**:
    
    $$
    ∆_{metric} = Metric_{position} - Metric_{zero-shot}
    $$
    
    该指标衡量在特定位置放置示例相对于零样本（zero-shot）基线的净性能增益。它清晰地显示了ICL在不同位置下的“有效性”。
    
2. **预测变化率 (Prediction Change, \(∆_{pred}\))**:
    
    $$
    ∆_{pred} = \frac{\#answer \\ flips}{\#Q}
    $$
    
    该指标衡量当示例位置从默认的 `sum` 移动到其他位置时，模型预测结果发生改变的样本比例。这是一个衡量**输出不稳定性**或**波动性**（volatility）的关键指标，即使在整体准确率变化不大的情况下，高 \(∆_{pred}\) 也意味着模型决策边界的剧烈扰动。
    

这两个指标的引入是本研究方法论上的一大亮点，它们共同构成了对DPP偏见“效果”与“副作用”的完整度量。

## **3. 实验设计与结果分析**

本研究的实验部分以其**广度**和**深度**令人印象深刻，覆盖了4个模型家族（QWEN, LLAMA3, MISTRAL, COHERE）的10个不同规模（1.5B到72B）的模型，以及8个跨越不同能力的NLP任务（分类、问答、摘要、推理）。

<figure>
  <img src="https://cdn.jsdelivr.net/gh/gongzitaiyi/picture@master/uPic/2025/12/W3twza.png" alt="图 1：在prompt中的四种配置（DPP）">
  <figcaption style="text-align: center;">图 1：在prompt中的四种配置（DPP）</figcaption>
</figure>


### **3.1 核心发现：显著的“首位效应”与“末位惩罚”**

实验结果揭示了一个一致且强烈的模式：

- **首位效应 (Primacy Effect)**：将示例放置在提示语的早期位置（`ssp` 和 `esp`）通常能获得最高且最稳定的性能。如图2所示，在多个分类任务中，`ssp` 位置带来的准确率提升（Accuracy Change）普遍高于其他位置。
- **末位惩罚 (Recency Penalty)**：将示例放置在用户查询之后（`eum`）表现最差。它不仅常常导致性能低于其他ICL位置，甚至有时会低于zero-shot基线。更严重的是，`eum` 位置会引发剧烈的预测波动。如图1和图3所示，`eum` 位置可导致高达45.5%的预测发生翻转，而这些翻转往往并未带来正确率的提升。

<!-- <figure>
  <img src="https://cdn.jsdelivr.net/gh/gongzitaiyi/picture@master/uPic/2025/12/0KaIKC.png" alt="图2：四个DPP在四个数据集上的准确率变化">
  <figcaption style="text-align: center;"><图2：四个DPP在四个数据集上的准确率变化/figcaption>
</figure>
<figure>
  <img src="https://cdn.jsdelivr.net/gh/gongzitaiyi/picture@master/uPic/2025/12/t7TDvT.png" alt="图3：三个DPP（不包括总和）在四个数据集上的预测变化（与总和相比）比率">
  <figcaption style="text-align: center;">图3：三个DPP（不包括总和）在四个数据集上的预测变化（与总和相比）比率</figcaption>
</figure> -->
<div style="display: flex; gap: 20px; justify-content: center; flex-wrap: wrap;">
  <figure style="flex: 1; min-width: 300px; margin: 0;">
    <img src="https://cdn.jsdelivr.net/gh/gongzitaiyi/picture@master/uPic/2025/12/0KaIKC.png" alt="图2：四个DPP在四个数据集上的准确率变化" style="width: 100%;">
    <figcaption style="text-align: center;">图2：四个DPP在四个数据集上的准确率变化</figcaption>
  </figure>
  <figure style="flex: 1; min-width: 300px; margin: 0;">
    <img src="https://cdn.jsdelivr.net/gh/gongzitaiyi/picture@master/uPic/2025/12/t7TDvT.png" alt="图3：三个DPP（不包括总和）在四个数据集上的预测变化（与总和相比）比率" style="width: 100%;">
    <figcaption style="text-align: center;">图3：三个DPP（不包括总和）在四个数据集上的预测变化（与总和相比）比率</figcaption>
  </figure>
</div>


### **3.2 统计显著性与波动性深度分析**

为了确保观察到的性能差异并非偶然，并更深入地理解预测波动，论文进行了细致的统计检验和可视化分析。

<div style="display: flex; gap: 20px; justify-content: center; flex-wrap: wrap;">
  <figure style="flex: 1; min-width: 300px; margin: 0;">
    <img src="https://cdn.jsdelivr.net/gh/gongzitaiyi/picture@master/uPic/2025/12/0KyUr3.png" alt="" style="width: 100%;">
    <figcaption style="text-align: center;">表1</figcaption>
  </figure>
  <figure style="flex: 1; min-width: 300px; margin: 0;">
    <img src="https://cdn.jsdelivr.net/gh/gongzitaiyi/picture@master/uPic/2025/12/j3glvO.png" alt="" style="width: 100%;">
    <figcaption style="text-align: center;">表2</figcaption>
  </figure>
</div>


- **统计稳健性验证**：在第4.5节和表1、表2中，作者采用了**配对的威尔科克森符号秩检验（Paired Wilcoxon signed-rank test）**。结果（以MMLU任务为例）显示，`ssp`、`esp`、`sum` 这三个位置的性能相较于零样本基线有**极显著的提升**（p < 0.01），而 `eum` 位置的提升则**不具备统计显著性**。更进一步的配对比较显示，`eum` 的性能显著劣于其他三个位置（p < 0.05）。这为“首位效应”和“末位惩罚”提供了强有力的统计学证据，证明了这些发现的可靠性。
- **Sankey图揭示的内在波动**：论文中的Sankey图（如Fig. 5-7）是理解预测波动性的关键。它们直观地展示了当示例位置改变时，预测结果从“正确”到“错误”（C→I）、“错误”到“正确”（I→C）的具体流向。以图6为例，我们可以看到，即使 `esp` 位的净准确率仅比 `sum` 位高一点，其内部却发生了剧烈的变化：大量的样本从正确变为错误，同时又有大量的样本从错误变为正确。这揭示了一个惊人的事实：**即使宏观准确率看似稳定，模型底层的决策逻辑可能已经天翻地覆。** 这也凸显了 \(∆_{pred}\) 指标的重要性，它捕捉了这种被传统准确率指标所掩盖的“隐性不稳定性”。

<figure>
  <img src="https://cdn.jsdelivr.net/gh/gongzitaiyi/picture@master/uPic/2025/12/ONG3LO.png" alt="">
  <figcaption style="text-align: center;"></figcaption>
</figure>

<figure>
  <img src="https://cdn.jsdelivr.net/gh/gongzitaiyi/picture@master/uPic/2025/12/x3YaQN.png" alt="">
  <figcaption style="text-align: center;"></figcaption>
</figure>

<figure>
  <img src="https://cdn.jsdelivr.net/gh/gongzitaiyi/picture@master/uPic/2025/12/8vlirr.png" alt="">
  <figcaption style="text-align: center;"></figcaption>
</figure>


### **3.3 规模的影响：非线性的伸缩法则**

论文通过对不同尺寸模型的分析，揭示了DPP偏见与模型规模的复杂关系：

- **普遍趋势**：更大的模型通常表现出更强的**位置鲁棒性**，即不同位置间的性能差异和预测波动性会减小（如图4所示）。
- **非单调变化**：有趣的是，最佳位置并非随模型增大而固定。在GSM8K算术推理任务中，小型模型在 `ssp` 处表现最佳，而LLAMA3-70B这样的大型模型却在 `eum` 位置获得了惊人的性能提升（从21.5%提升至88%）。


<div style="display: flex; gap: 10px; justify-content: center; flex-wrap: wrap;">
  <figure style="flex: 1; min-width: 300px; margin: 0;">
    <img src="https://cdn.jsdelivr.net/gh/gongzitaiyi/picture@master/uPic/2025/12/v0eqDM.png" alt="" style="width: 100%;">
    <figcaption style="text-align: center;">图4:（a）四个 DPP 在 MMLU 上的预测变化（与总和相比）：随着模型规模的增加而下降</figcaption>
  </figure>
  <figure style="flex: 1; min-width: 300px; margin: 0;">
    <img src="https://cdn.jsdelivr.net/gh/gongzitaiyi/picture@master/uPic/2025/12/g61obL.png" alt="" style="width: 100%;">
    <figcaption style="text-align: center;">（b）四个DPP在MMLU上的准确性变化（相对于零-shot的改进）：随着模型规模的增加而下降</figcaption>
  </figure>
</div>


> 📊 **结果解释**: 这种非单调的规模效应是一个值得深思的发现。作者推测这与模型能力有关，即大模型可能拥有更强的能力来“回顾”并整合位于查询之后的信息。然而，另一种可能性是，对于某些特定任务（如结构化推理），将示例放在最后，能够让模型在完成对查询的初步解析后，再将示例作为一种“解题模板”或“格式参考”，从而表现更佳。这究竟是一种通用的涌现能力，还是特定模型与特定任务结构耦合的产物？
> 

### **3.4 任务与模型的特异性：不存在“万能钥匙”**

通过详尽的“胜-平-负”（win-tie-loss）分析（如图8-10），论文有力地证明了**不存在一个普遍最优的示例位置**。最佳位置是**模型相关**且**任务相关**的。


<figure>
  <img src="https://cdn.jsdelivr.net/gh/gongzitaiyi/picture@master/uPic/2025/12/BllO8e.png" alt="">
  <figcaption style="text-align: center;"></figcaption>
</figure>

<figure>
  <img src="https://cdn.jsdelivr.net/gh/gongzitaiyi/picture@master/uPic/2025/12/PXyNJO.png" alt="">
  <figcaption style="text-align: center;"></figcaption>
</figure>

<figure>
  <img src="https://cdn.jsdelivr.net/gh/gongzitaiyi/picture@master/uPic/2025/12/O4q6DR.png" alt="">
  <figcaption style="text-align: center;"></figcaption>
</figure>


> ⚠️ **数据关注**: 整个研究的实验都基于`k=5`个示例。ICL的性能同样对示例数量`k`敏感（即所谓的“k-shot sensitivity”）。研究结论在多大程度上依赖于`k=5`这一设定？例如，在`k=1`的单示例场景下，位置效应是否会被放大或削弱？在`k`值更大（如`k=10`）时，模型是否会因为上下文窗口的压力而表现出不同的位置偏好？这是一个重要的、可能影响结论普适性的控制变量。
> 

## **4. 主要贡献与创新总结**

Cobbina与Zhou的这项工作为ICL领域带来了以下关键贡献：

1. **识别并定义新偏见**：首次系统性地揭示了“Demos' Position in Prompt (DPP) bias”，填补了ICL敏感性研究的重要空白。
2. **构建严谨评估框架**：提出了一套包含规范化位置定义、创新诊断指标（\(∆_{metric}\)， \(∆_{pred}\)）以及统计验证方法的评估流水线，为后续研究提供了标准化的工具。
3. **提供大规模经验证据**：通过跨模型、跨任务的详尽实验，证实了DPP偏见的普遍存在，并揭示了其与模型规模、任务类型的复杂交互关系。
4. **深化对ICL机制的理解**：研究结果为解释LLM的内在机制（如注意力机制的“首位效应”和“中间遗忘”）提供了新的、角度独特的经验证据。
5. **提供实践指导与警示**：明确指出不存在“一招鲜”的最佳示例位置，强调了提示工程必须是模型和任务感知的，并警示从业者不能忽视提示语的宏观结构。

## **5. 局限性与未来方向讨论**

> 💭 **理论思考**: 论文将DPP偏见的根源归结为**架构原因**（自回归模型的内在特性）和**数据原因**（指令微调语料中固定的模板格式）。未来的研究可以通过精心设计的实验来解耦这两个因素。例如，在一个完全不含固定格式、示例位置完全随机的语料上从头预训练一个模型，观察其是否仍然表现出类似的位置偏见。
> 

> 🌐 **应用局限与商业价值**:
> 
> - **商业闭源模型**：本研究聚焦于开源模型。像GPT-4、Claude 3等顶尖商业模型，经过更复杂的对齐和微调，是否能更好地克服这种位置偏见？或者它们会展现出新的、不同的偏好模式？验证这一点对于企业级应用至关重要。
> - **实际应用启示**：这一发现对构建RAG（检索增强生成）系统、AI Agent以及提示市场（Prompt Marketplace）有直接影响。例如，RAG系统在将检索到的知识片段注入提示时，应将其放在`ssp`或`esp`位置以获得最佳效果。提示工程师在设计和售卖提示时，不仅要优化内容，还必须明确标注其最佳结构和位置。
> - **低成本缓解策略**：作者提出的缓解策略成本较高。未来可以探索更轻量级的方法，如通过**元指令**（meta-instruction）引导模型注意力（例如，在提示语中加入“请仔细研究以下示例，然后回答最后的问题”）。

> 🔍 **方法论拓展**:
> 
> - **多模态场景**：位置偏见在视觉-语言模型中将如何表现？当提示包含交错的文本和图像时，图像的位置、文本示例的位置，它们之间会产生怎样的交互效应？这是一个全新的前沿领域。
> - **思维链（CoT）的扩展**：该研究聚焦于标准的输入-输出示例。对于包含复杂推理过程的思维链（Chain-of-Thought, CoT）示例，位置效应可能更为复杂。将一个详细的CoT示例放在开头（`ssp`），是否能更有效地引导模型学习推理“范式”？反之，将其放在最后（`eum`），是否可能干扰模型对当前问题的独立思考？
